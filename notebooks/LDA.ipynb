{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e2860d-f53c-4d3e-af09-2c51fe01a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202b7a42-e544-4177-9d57-b91f283a4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import torch\n",
    "# Set default tensor type to float64\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e47e089-7a7a-4889-89f1-258bc2103f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat(\"data/lda/lda_on_grid.mat\")\n",
    "data = data[\"lda_on_grid\"]\n",
    "X = torch.tensor(data[:, :3])\n",
    "X[:, 0] = 2.0 * X[:, 0] - 1.0\n",
    "X[:, 1] = torch.log2(X[:, 1]) / 10.0\n",
    "X[:, 2] = torch.log2(X[:, 2]) / 14.0\n",
    "objective_X = -torch.tensor(data[:, 3]).unsqueeze(-1)\n",
    "cost_X = torch.tensor(data[:, 4]).unsqueeze(-1) / 3600.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c737fea-61eb-4d83-8d6c-928ae15c25b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 3\n",
    "maximize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951f341c-62f0-4cca-903f-407df2434938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandora_bayesopt.utils import fit_gp_model\n",
    "objective_model = fit_gp_model(X, objective_X, input_standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ae7eec3-53b6-4708-863e-7df4edaa40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(X):\n",
    "    if X.ndim == 1:\n",
    "        X = X.unsqueeze(0)\n",
    "    posterior_X = objective_model.posterior(X)\n",
    "    objective_X = posterior_X.mean.detach()\n",
    "    return 0.001*objective_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df2e7ce-4281-4abc-bfe4-5720bbd97b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SingleTaskGP(\n",
       "  (likelihood): FixedNoiseGaussianLikelihood(\n",
       "    (noise_covar): FixedGaussianNoise()\n",
       "  )\n",
       "  (mean_module): ConstantMean()\n",
       "  (covar_module): ScaleKernel(\n",
       "    (base_kernel): MaternKernel(\n",
       "      (lengthscale_prior): GammaPrior()\n",
       "      (raw_lengthscale_constraint): Positive()\n",
       "    )\n",
       "    (outputscale_prior): GammaPrior()\n",
       "    (raw_outputscale_constraint): Positive()\n",
       "  )\n",
       "  (outcome_transform): Standardize()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7234855f-ebb6-4015-8f74-3eefbc0c02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_cost_X = torch.log(cost_X)\n",
    "log_cost_model = fit_gp_model(X, log_cost_X, input_standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ebf18f9-bfe3-4a97-b74f-93d4234b8227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X):\n",
    "    posterior_X = log_cost_model.posterior(X)\n",
    "    cost_X = torch.exp(posterior_X.mean)\n",
    "    return cost_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd96fff-b023-48c4-a74c-5968ace6f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "budget = 5\n",
    "seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d6bbd8-f0b6-4818-a634-9336476af65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.acquisition import ExpectedImprovement\n",
    "from pandora_bayesopt.acquisition.gittins import GittinsIndex\n",
    "from pandora_bayesopt.acquisition.ei_puc import ExpectedImprovementWithCost\n",
    "from pandora_bayesopt.bayesianoptimizer import BayesianOptimizer\n",
    "from botorch.utils.sampling import draw_sobol_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebec3c0-02e4-48d5-9b40-bf2fa378dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_optimum_value = -1.2606842790227435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6924af8-1622-4a3e-bbfa-7e65f8837103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.57766536 0.57438965 0.75741616], New value: -1.2984029632645637\n",
      "Best observed value: -1.2704712372093203\n",
      "Current acquisition value: tensor(0.0894)\n",
      "Cumulative cost: 4.182386782394579\n",
      "\n",
      "Iteration 1, New point: [0.20091817 0.29102848 0.87349667], New value: -1.2885565059815858\n",
      "Best observed value: -1.2704712372093203\n",
      "Current acquisition value: tensor(0.0570)\n",
      "Cumulative cost: 7.379394895636061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Example usage with EI\n",
    "EI_optimizer = BayesianOptimizer(objective=objective_function, dim=dim, maximize=maximize, cost=cost_function, initial_points=init_x, input_standardize=True)\n",
    "EI_optimizer.run_until_budget(budget=budget, acquisition_function_class=ExpectedImprovement)\n",
    "EI_best_history = EI_optimizer.get_best_history()\n",
    "EI_regret_history = EI_optimizer.get_regret_history(global_optimum_value)\n",
    "EI_cost_history = EI_optimizer.get_cost_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15563259-752a-447e-8952-eaee5f63b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.102708568121024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/transforms/outcome.py:304: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  stdvs = Y.std(dim=-2, keepdim=True)\n",
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Expected the output shape to match either the t-batch shape of X, or the `model.batch_shape` in the case of acquisition functions using batch models; but got output with shape torch.Size([5, 5]) for X with shape torch.Size([5, 1, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Example usage with BMSEI\u001b[39;00m\n\u001b[1;32m      8\u001b[0m BMSEI_optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimizer(objective\u001b[38;5;241m=\u001b[39mobjective_function, dim\u001b[38;5;241m=\u001b[39mdim, maximize\u001b[38;5;241m=\u001b[39mmaximize, cost\u001b[38;5;241m=\u001b[39mcost_function, initial_points\u001b[38;5;241m=\u001b[39minit_x, input_standardize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mBMSEI_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_budget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macquisition_function_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBudgetedMultiStepLookaheadEI\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m BMSEI_best_history \u001b[38;5;241m=\u001b[39m BMSEI_optimizer\u001b[38;5;241m.\u001b[39mget_best_history()\n\u001b[1;32m     11\u001b[0m BMSEI_regret_history \u001b[38;5;241m=\u001b[39m BMSEI_optimizer\u001b[38;5;241m.\u001b[39mget_regret_history(global_optimum_value)\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandora_bayesopt/bayesianoptimizer.py:283\u001b[0m, in \u001b[0;36mBayesianOptimizer.run_until_budget\u001b[0;34m(self, budget, acquisition_function_class, **acqf_kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_cost \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbudget:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43macquisition_function_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43macqf_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_iteration_info(i)\n\u001b[1;32m    285\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandora_bayesopt/bayesianoptimizer.py:192\u001b[0m, in \u001b[0;36mBayesianOptimizer.iterate\u001b[0;34m(self, acquisition_function_class, **acqf_kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    191\u001b[0m q \u001b[38;5;241m=\u001b[39m acq_function\u001b[38;5;241m.\u001b[39mget_augmented_q_batch_size(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_ms \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 192\u001b[0m candidates, candidates_acq_vals \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_acqf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_limit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_initial_conditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_initial_conditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_full_tree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m candidates \u001b[38;5;241m=\u001b[39m  candidates\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_ms:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# save all tree variables for multi-step initialization\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/optim/optimize.py:563\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m     gen_candidates \u001b[38;5;241m=\u001b[39m gen_candidates_scipy\n\u001b[1;32m    541\u001b[0m opt_acqf_inputs \u001b[38;5;241m=\u001b[39m OptimizeAcqfInputs(\n\u001b[1;32m    542\u001b[0m     acq_function\u001b[38;5;241m=\u001b[39macq_function,\n\u001b[1;32m    543\u001b[0m     bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m     ic_gen_kwargs\u001b[38;5;241m=\u001b[39mic_gen_kwargs,\n\u001b[1;32m    562\u001b[0m )\n\u001b[0;32m--> 563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_acqf_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/optim/optimize.py:584\u001b[0m, in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _optimize_acqf_sequential_q(opt_inputs\u001b[38;5;241m=\u001b[39mopt_inputs)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Batch optimization (including the case q=1)\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_optimize_acqf_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/optim/optimize.py:274\u001b[0m, in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    271\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m opt_inputs\u001b[38;5;241m.\u001b[39mbatch_initial_conditions\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m# pyre-ignore[28]: Unexpected keyword argument `acq_function` to anonymous call.\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m     batch_initial_conditions \u001b[38;5;241m=\u001b[39m \u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ic_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43macq_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macq_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_restarts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_restarts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43minequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mequality_constraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequality_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_inputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mic_gen_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m batch_limit: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_limit\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    289\u001b[0m     opt_inputs\u001b[38;5;241m.\u001b[39mnum_restarts\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_inputs\u001b[38;5;241m.\u001b[39mnonlinear_inequality_constraints\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_optimize_batch_candidates\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor, List[\u001b[38;5;167;01mWarning\u001b[39;00m]]:\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/optim/initializers.py:417\u001b[0m, in \u001b[0;36mgen_batch_initial_conditions\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, fixed_features, options, inequality_constraints, equality_constraints, generator, fixed_X_fantasies)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m start_idx \u001b[38;5;241m<\u001b[39m X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    416\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start_idx \u001b[38;5;241m+\u001b[39m batch_limit, X_rnd\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 417\u001b[0m     Y_rnd_curr \u001b[38;5;241m=\u001b[39m \u001b[43macq_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_rnd\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    420\u001b[0m     Y_rnd_list\u001b[38;5;241m.\u001b[39mappend(Y_rnd_curr)\n\u001b[1;32m    421\u001b[0m     start_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_limit\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/utils/transforms.py:259\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    258\u001b[0m X \u001b[38;5;241m=\u001b[39m X \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43macqf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(acqf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_ensemble(acqf\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    263\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    264\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/acquisition/multi_step_lookahead.py:185\u001b[0m, in \u001b[0;36mqMultiStepLookahead.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collapse_fantasy_base_samples:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_samplers_batch_range(batch_shape\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamplers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamplers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalfunc_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_valfunc_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalfunc_argfacs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_valfunc_argfacs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_samplers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_samplers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/acquisition/multi_step_lookahead.py:372\u001b[0m, in \u001b[0;36m_step\u001b[0;34m(model, Xs, samplers, valfunc_cls, valfunc_argfacs, inner_samplers, objective, posterior_transform, running_val, sample_weights, step_index)\u001b[0m\n\u001b[1;32m    369\u001b[0m     sample_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m*\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m], device\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# compute stage value\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m stage_val \u001b[38;5;241m=\u001b[39m \u001b[43m_compute_stage_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalfunc_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalfunc_cls\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposterior_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposterior_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43minner_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_samplers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_fac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalfunc_argfacs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# update running value\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;66;03m# if not None, running_val has shape f_{i-1} x ... x f_1 x batch_shape\u001b[39;00m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;66;03m# stage_val has shape f_i x ... x f_1 x batch_shape\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# this sum will add a dimension to running_val so that\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# updated running_val has shape f_i x ... x f_1 x batch_shape\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     running_val \u001b[38;5;241m=\u001b[39m stage_val \u001b[38;5;28;01mif\u001b[39;00m running_val \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m running_val \u001b[38;5;241m+\u001b[39m stage_val\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/acquisition/multi_step_lookahead.py:468\u001b[0m, in \u001b[0;36m_compute_stage_value\u001b[0;34m(model, valfunc_cls, X, objective, posterior_transform, inner_sampler, arg_fac)\u001b[0m\n\u001b[1;32m    466\u001b[0m stage_val_func \u001b[38;5;241m=\u001b[39m valfunc_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# shape of stage_val is f_i x ... x f_1 x batch_shape\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m stage_val \u001b[38;5;241m=\u001b[39m \u001b[43mstage_val_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stage_val\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOPT/pandorabayesopt_env/lib/python3.9/site-packages/botorch/utils/transforms.py:270\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    263\u001b[0m         output\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acqf\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;28;01melse\u001b[39;00m logmeanexp(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m assert_output_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _verify_output_shape(\n\u001b[1;32m    266\u001b[0m     acqf\u001b[38;5;241m=\u001b[39macqf,\n\u001b[1;32m    267\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    268\u001b[0m     output\u001b[38;5;241m=\u001b[39moutput,\n\u001b[1;32m    269\u001b[0m ):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the output shape to match either the t-batch shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX, or the `model.batch_shape` in the case of acquisition \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions using batch models; but got output with shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for X with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[0;31mAssertionError\u001b[0m: Expected the output shape to match either the t-batch shape of X, or the `model.batch_shape` in the case of acquisition functions using batch models; but got output with shape torch.Size([5, 5]) for X with shape torch.Size([5, 1, 3])."
     ]
    }
   ],
   "source": [
    "from pandora_bayesopt.acquisition.budgeted_multi_step_ei import BudgetedMultiStepLookaheadEI\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "init_x = torch.rand(1, dim)\n",
    "\n",
    "# Example usage with BMSEI\n",
    "BMSEI_optimizer = BayesianOptimizer(objective=objective_function, dim=dim, maximize=maximize, cost=cost_function, initial_points=init_x, input_standardize=True)\n",
    "BMSEI_optimizer.run_until_budget(budget=budget, acquisition_function_class=BudgetedMultiStepLookaheadEI)\n",
    "BMSEI_best_history = BMSEI_optimizer.get_best_history()\n",
    "BMSEI_regret_history = BMSEI_optimizer.get_regret_history(global_optimum_value)\n",
    "BMSEI_cost_history = BMSEI_optimizer.get_cost_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
