{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# use a GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set default tensor type to float64\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.test_functions.synthetic import Ackley\n",
    "from botorch.utils.sampling import draw_sobol_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=4\n",
    "ackley_function = Ackley(dim=dim)\n",
    "scale_factor = -1\n",
    "def objective_function(X):\n",
    "    return ackley_function(2*X-1)/scale_factor\n",
    "global_optimum_value = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = init_x\n",
    "exact_Y = objective_function(init_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_SE = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = exact_Y + NOISE_SE * torch.randn_like(exact_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExactMarginalLogLikelihood(\n",
       "  (likelihood): FixedNoiseGaussianLikelihood(\n",
       "    (noise_covar): FixedGaussianNoise()\n",
       "  )\n",
       "  (model): SingleTaskGP(\n",
       "    (likelihood): FixedNoiseGaussianLikelihood(\n",
       "      (noise_covar): FixedGaussianNoise()\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (lengthscale_prior): GammaPrior()\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (outputscale_prior): GammaPrior()\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "    (outcome_transform): Standardize()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Yvar = torch.full_like(train_Y, NOISE_SE**2)\n",
    "\n",
    "if train_X.ndim == 1:\n",
    "    train_x = train_X.unsqueeze(dim=-1)\n",
    "\n",
    "if train_Y.ndim == 1:\n",
    "    train_Y = train_Y.unsqueeze(dim=-1)\n",
    "\n",
    "# Outcome transform\n",
    "outcome_transform = Standardize(m=train_Y.shape[-1])\n",
    "\n",
    "model = SingleTaskGP(train_X=train_X, train_Y=train_Y, train_Yvar=train_Yvar, outcome_transform=outcome_transform)\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "fit_gpytorch_model(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SingleTaskGP:\n\tUnexpected key(s) in state_dict: \"outcome_transform.means\", \"outcome_transform.stdvs\", \"outcome_transform._stdvs_sq\", \"outcome_transform._is_trained\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01macquisition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalytic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NoisyExpectedImprovement\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_acqf\n\u001b[0;32m----> 4\u001b[0m NEI \u001b[38;5;241m=\u001b[39m \u001b[43mNoisyExpectedImprovement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m new_point, new_point_NEI \u001b[38;5;241m=\u001b[39m optimize_acqf(\n\u001b[1;32m      6\u001b[0m         acq_function\u001b[38;5;241m=\u001b[39mNEI,\n\u001b[1;32m      7\u001b[0m         bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/acquisition/analytic.py:712\u001b[0m, in \u001b[0;36mNoisyExpectedImprovement.__init__\u001b[0;34m(self, model, X_observed, num_fantasies, maximize)\u001b[0m\n\u001b[1;32m    710\u001b[0m batch_X_observed \u001b[38;5;241m=\u001b[39m X_observed\u001b[38;5;241m.\u001b[39mexpand(num_fantasies, \u001b[38;5;241m*\u001b[39mX_observed\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# The fantasy model will operate in batch mode\u001b[39;00m\n\u001b[0;32m--> 712\u001b[0m fantasy_model \u001b[38;5;241m=\u001b[39m \u001b[43m_get_noiseless_fantasy_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_X_observed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_X_observed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_fantasized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_fantasized\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m best_f, _ \u001b[38;5;241m=\u001b[39m Y_fantasized\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m maximize \u001b[38;5;28;01melse\u001b[39;00m Y_fantasized\u001b[38;5;241m.\u001b[39mmin(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model\u001b[38;5;241m=\u001b[39mfantasy_model, best_f\u001b[38;5;241m=\u001b[39mbest_f, maximize\u001b[38;5;241m=\u001b[39mmaximize)\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/acquisition/analytic.py:1088\u001b[0m, in \u001b[0;36m_get_noiseless_fantasy_model\u001b[0;34m(model, batch_X_observed, Y_fantasized)\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;66;03m# load hyperparameters from original model\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m deepcopy(model\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[0;32m-> 1088\u001b[0m \u001b[43mfantasy_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fantasy_model\n",
      "File \u001b[0;32m~/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SingleTaskGP:\n\tUnexpected key(s) in state_dict: \"outcome_transform.means\", \"outcome_transform.stdvs\", \"outcome_transform._stdvs_sq\", \"outcome_transform._is_trained\". "
     ]
    }
   ],
   "source": [
    "from botorch.acquisition.analytic import NoisyExpectedImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "\n",
    "NEI = NoisyExpectedImprovement(model, train_X)\n",
    "new_point, new_point_NEI = optimize_acqf(\n",
    "        acq_function=NEI,\n",
    "        bounds=bounds,\n",
    "        q=1,\n",
    "        num_restarts=10*dim,\n",
    "        raw_samples=200*dim,\n",
    "        options={'method': 'L-BFGS-B'},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandorabayesopt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
