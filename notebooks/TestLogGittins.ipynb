{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcc30f5-8177-4caf-9894-76de754c393a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:194: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/ReduceOps.cpp:1760.)\n",
      "  Ymean, Ystd = torch.mean(Y, dim=-2), torch.std(Y, dim=-2)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# use a GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set default tensor type to float64\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "seed = 0\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "import torch\n",
    "import gpytorch\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.likelihoods import FixedNoiseGaussianLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "\n",
    "# Example Usage for 1D\n",
    "dim = 4\n",
    "\n",
    "# Define your kernel\n",
    "nu = 2.5\n",
    "lengthscale = 0.1\n",
    "outputscale = 1.0\n",
    "base_kernel = MaternKernel(nu=nu).double()\n",
    "base_kernel.lengthscale = torch.tensor([[lengthscale]])\n",
    "scale_kernel = ScaleKernel(base_kernel).double()\n",
    "scale_kernel.outputscale = torch.tensor([[outputscale]])\n",
    "\n",
    "# Define Noise Level\n",
    "noise_level = 1e-4\n",
    "\n",
    "# Initialize Placeholder Data with Correct Dimensions\n",
    "num_samples = 1  # Replace with actual number of samples\n",
    "num_features = dim  # Replace with actual number of features\n",
    "train_X = torch.empty(num_samples, num_features)  # Placeholder data\n",
    "train_Y = torch.empty(num_samples, 1)             # Placeholder data\n",
    "Yvar = torch.ones(num_samples) * noise_level\n",
    "\n",
    "# Initialize Model\n",
    "model = SingleTaskGP(train_X, train_Y, likelihood = FixedNoiseGaussianLikelihood(noise=Yvar), covar_module=scale_kernel)\n",
    "\n",
    "from botorch.sampling.pathwise import draw_kernel_feature_paths\n",
    "matern_sample = draw_kernel_feature_paths(model, sample_shape=torch.Size([1]))\n",
    "def objective_function(x):\n",
    "    return matern_sample(x).squeeze(0).detach()\n",
    "\n",
    "from botorch.utils.sampling import optimize_posterior_samples\n",
    "# Find the global optimum\n",
    "maximize = True\n",
    "bounds = torch.stack([torch.zeros(dim), torch.ones(dim)])\n",
    "global_optimum_point, global_optimum_value = optimize_posterior_samples(paths=matern_sample, bounds=bounds, raw_samples=1024*dim, num_restarts=20*dim, maximize=maximize)\n",
    "\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "# Set up the kernel\n",
    "base_kernel = MaternKernel(nu=nu).double()\n",
    "base_kernel.lengthscale = lengthscale\n",
    "base_kernel.raw_lengthscale.requires_grad = False\n",
    "scale_kernel = ScaleKernel(base_kernel).double()\n",
    "scale_kernel.outputscale = torch.tensor([[outputscale]])\n",
    "scale_kernel.raw_outputscale.requires_grad = False\n",
    "\n",
    "maximize = True\n",
    "output_standardize = False\n",
    "\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from pandora_bayesopt.bayesianoptimizer import BayesianOptimizer\n",
    "from botorch.acquisition import LogExpectedImprovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8febff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.2982]), std = tensor([0.9299])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.         0.27414241 0.77417126 0.02928116], New value: -1.3432093708360693\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.287264330692003\n",
      "Cumulative cost: 1.0\n",
      "Running time: 8.263291\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3932]), std = tensor([0.9368])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, New point: [0.97261306 0.88430817 0.8006507  0.67954832], New value: 0.09211499885115043\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.1169288839850147\n",
      "Cumulative cost: 2.0\n",
      "Running time: 9.808105999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandora_bayesopt.acquisition.log_gittins import LogGittinsIndex\n",
    "num_iterations = 2\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Create an instance of BayesianOptimizer\n",
    "logPBGI_optimizer = BayesianOptimizer( \n",
    "        dim=dim, \n",
    "        maximize=maximize, \n",
    "        initial_points=init_x,\n",
    "        objective=objective_function, \n",
    "        output_standardize=output_standardize\n",
    "    )\n",
    "# Run the optimization\n",
    "logPBGI_optimizer.run(\n",
    "            num_iterations = num_iterations, \n",
    "            acquisition_function_class = LogGittinsIndex,\n",
    "            lmbda = 0.0001\n",
    "        )\n",
    "logPBGI_best_history = logPBGI_optimizer.get_best_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4f3124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.2982]), std = tensor([0.9299])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, New point: [0.         0.27414241 0.77417126 0.02928116], New value: -1.3432093708361468\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.2872643306920004\n",
      "Cumulative cost: 1.0\n",
      "Running time: 3.928711\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qianxie/Desktop/Curriculum/Graduate/Research/PandoraBayesOpt/pandorabayesopt_env/lib/python3.9/site-packages/botorch/models/utils/assorted.py:202: InputDataWarning: Input data is not standardized (mean = tensor([-0.3932]), std = tensor([0.9368])). Please consider scaling the input to zero mean and unit variance.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, New point: [0.97261306 0.88430817 0.8006507  0.67954832], New value: 0.09211499885101987\n",
      "Best observed value: 0.799035898007519\n",
      "Current acquisition value: 3.116928883985035\n",
      "Cumulative cost: 2.0\n",
      "Running time: 4.429997999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pandora_bayesopt.acquisition.gittins import GittinsIndex\n",
    "num_iterations = 2\n",
    "init_x = draw_sobol_samples(bounds=bounds, n=1, q=2*(dim+1)).squeeze(0)\n",
    "\n",
    "# Create an instance of BayesianOptimizer\n",
    "PBGI_optimizer = BayesianOptimizer( \n",
    "        dim=dim, \n",
    "        maximize=maximize, \n",
    "        initial_points=init_x,\n",
    "        objective=objective_function, \n",
    "        output_standardize=output_standardize\n",
    "    )\n",
    "# Run the optimization\n",
    "PBGI_optimizer.run(\n",
    "            num_iterations = num_iterations, \n",
    "            acquisition_function_class = GittinsIndex,\n",
    "            lmbda = 0.0001\n",
    "        )\n",
    "PBGI_best_history = PBGI_optimizer.get_best_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
