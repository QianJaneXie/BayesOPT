{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "def load_impact_of_lmbda_runs(acq):\n",
    "    runs = api.runs(path=\"ziv-scully-group/PandoraBayesOPT\", filters={\n",
    "        \"sweep\": \"xcn0phan\",\n",
    "        \"config.amplitude\": 1,\n",
    "        \"config.dim\": 8,\n",
    "        \"config.kernel\": \"Matern52\",\n",
    "        \"config.lengthscale\": 0.1,  \n",
    "        \"config.policy\": acq})\n",
    "    \n",
    "    configs_and_metrics = []\n",
    "    for run in tqdm(runs):\n",
    "        metric_keys = [\"cumulative cost\",\"best observed\",\"lmbda\"]\n",
    "        history = run.scan_history(keys = metric_keys, page_size=1_000_000_000)\n",
    "        metrics = {k: [d[k] for d in history] for k in metric_keys}\n",
    "        summary_metric_keys = [\"global optimum value\"]\n",
    "        summary_history = run.scan_history(keys = summary_metric_keys, page_size=1_000_000_000)\n",
    "        metrics.update({k: [d[k] for d in summary_history] for k in summary_metric_keys})\n",
    "        configs_and_metrics.append((run.config, metrics))\n",
    "\n",
    "    return configs_and_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_functions = [\n",
    "    'Gittins_Lmbda_1_Step_Divide2',\n",
    "    'Gittins_Lmbda_1_Step_Divide10',\n",
    "    'Gittins_Lmbda_1_Step_Divide100',\n",
    "    'Gittins_Lmbda_0001_Step_Divide2',\n",
    "    'Gittins_Lmbda_0001_Step_Divide10',\n",
    "    'Gittins_Lmbda_0001_Step_Divide100'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [08:33<00:00,  2.00s/it]\n",
      "100%|██████████| 256/256 [08:37<00:00,  2.02s/it]\n",
      "100%|██████████| 256/256 [07:55<00:00,  1.86s/it]\n",
      "100%|██████████| 256/256 [07:03<00:00,  1.66s/it]\n",
      "100%|██████████| 256/256 [07:24<00:00,  1.74s/it]\n",
      " 64%|██████▍   | 165/256 [05:10<02:20,  1.55s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=19 sec). Create a new API with an integer timeout larger than 19, e.g., `api = wandb.Api(timeout=29)` to increase the graphql timeout.\n",
      " 72%|███████▏  | 184/256 [11:00<02:56,  2.45s/it]  \u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=19 sec). Create a new API with an integer timeout larger than 19, e.g., `api = wandb.Api(timeout=29)` to increase the graphql timeout.\n",
      " 84%|████████▍ | 215/256 [13:08<00:58,  1.44s/it]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=19 sec). Create a new API with an integer timeout larger than 19, e.g., `api = wandb.Api(timeout=29)` to increase the graphql timeout.\n",
      "100%|██████████| 256/256 [31:03<00:00,  7.28s/it]   \n"
     ]
    }
   ],
   "source": [
    "grouped_runs = {(a): load_impact_of_lmbda_runs(a) for a in acquisition_functions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gittins_Lmbda_1_Step_Divide2 (200, 256)\n",
      "Gittins_Lmbda_1_Step_Divide10 (200, 256)\n",
      "Gittins_Lmbda_1_Step_Divide100 (200, 256)\n",
      "Gittins_Lmbda_0001_Step_Divide2 (200, 256)\n",
      "Gittins_Lmbda_0001_Step_Divide10 (200, 256)\n",
      "Gittins_Lmbda_0001_Step_Divide100 (200, 256)\n"
     ]
    }
   ],
   "source": [
    "for a in acquisition_functions:\n",
    "    config_and_metrics_per_seed = grouped_runs[a]\n",
    "\n",
    "    cumulative_cost_per_seed = np.array([m['cumulative cost'] for (_,m) in config_and_metrics_per_seed]).T\n",
    "    best_observed_per_seed = np.array([m['best observed'] for (_,m) in config_and_metrics_per_seed]).T\n",
    "    # Handling potential empty arrays\n",
    "    if cumulative_cost_per_seed.size == 0 or best_observed_per_seed.size == 0:\n",
    "        continue  # Skip this iteration if there's no data\n",
    "    global_optimum_per_seed = np.array([m['global optimum value'][0] for (_,m) in config_and_metrics_per_seed if len(m['cumulative cost'])>0 and len(m['best observed'])>0])\n",
    "\n",
    "    regret_per_seed = global_optimum_per_seed - best_observed_per_seed\n",
    "    print(a, regret_per_seed.shape)\n",
    "\n",
    "    regret_25 = np.quantile(regret_per_seed, 0.25, axis=1)\n",
    "    regret_50 = np.quantile(regret_per_seed, 0.5, axis=1)\n",
    "    regret_75 = np.quantile(regret_per_seed, 0.75, axis=1)\n",
    "\n",
    "    output = np.stack((cumulative_cost_per_seed.mean(axis=1), regret_25, regret_50, regret_75),axis=-1)\n",
    "\n",
    "    np.savetxt(f\"results/gittins_step_divide_256/{a}.csv\", output, header=\"cc, q25, q50, q75\", delimiter=', ', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gittins_Lmbda_1_Step_Divide2 (200, 256)\n",
      "Gittins_Lmbda_1_Step_Divide10 (200, 256)\n",
      "Gittins_Lmbda_1_Step_Divide100 (200, 256)\n",
      "Gittins_Lmbda_0001_Step_Divide2 (200, 256)\n",
      "Gittins_Lmbda_0001_Step_Divide10 (200, 256)\n",
      "Gittins_Lmbda_0001_Step_Divide100 (200, 256)\n"
     ]
    }
   ],
   "source": [
    "for a in acquisition_functions:\n",
    "    config_and_metrics_per_seed = grouped_runs[a]\n",
    "\n",
    "    lmbda_per_seed = np.array([m['lmbda'] for (_,m) in config_and_metrics_per_seed]).T\n",
    "    # Handling potential empty arrays\n",
    "    if lmbda_per_seed.size == 0:\n",
    "        continue  # Skip this iteration if there's no data\n",
    "\n",
    "    print(a, lmbda_per_seed.shape)\n",
    "\n",
    "    lmbda_25 = np.quantile(lmbda_per_seed, 0.25, axis=1)\n",
    "    lmbda_50 = np.quantile(lmbda_per_seed, 0.5, axis=1)\n",
    "    lmbda_75 = np.quantile(lmbda_per_seed, 0.75, axis=1)\n",
    "\n",
    "    output = np.stack((cumulative_cost_per_seed.mean(axis=1), lmbda_25, lmbda_50, lmbda_75),axis=-1)\n",
    "\n",
    "    np.savetxt(f\"results/lmbda_history_256/{a}.csv\", output, header=\"cc, q25, q50, q75\", delimiter=', ', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
